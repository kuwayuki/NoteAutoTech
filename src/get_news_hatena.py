import os
from datetime import datetime, timedelta
from hatena_scraper import fetch_hatena_news_entries, fetch_article_content_from_url
from history_manager import (
    load_history,
    save_history_json,
    load_history_json,
)
from utils import simple
from post_note import main as post_note
from typing import List, Dict
import asyncio
import sys
import random

RANK_LIMIT = 2

# é­šæ‹“ã‚·ãƒªãƒ¼ã‚ºã«ä½¿ãˆã‚‹çµµæ–‡å­—ã®ãƒªã‚¹ãƒˆ
emoji_list = [
    "ğŸ£",
    "ğŸ£",
    "ğŸ£",
    "ğŸ£",
    "ğŸ£",
    "ğŸ£",  # é‡£ã‚Šå¤šã‚ã«
    "ğŸŸ",
    "ğŸ ",
    "ğŸ¦‘",
    "ğŸ¡",
    "ğŸ™",
    "ğŸ¦",
    "ğŸ³",
    "ğŸ‹",
    "ğŸª¼",  # æ‹¡å¼µï¼šæµ·ç³»ï¼‹æ°´ä¸­ç”Ÿç‰©
]

# ãƒ©ãƒ³ãƒ€ãƒ ã«1ã¤é¸ã¶
chosen_emoji = random.choice(emoji_list)
TEMPLATE_TITLE = (
    f"### {datetime.now().month}/{datetime.now().day} æŠ€è¡“é­šæ‹“{chosen_emoji}|"
    # f"# ã€{datetime.now().month}/{datetime.now().day} æŠ€è¡“é­šæ‹“{chosen_emoji}ã€‘"
)
# noteã®å¿ƒå¾—.mdã®ãƒ‘ã‚¹
NOTE_KOKOROE_PATH = os.path.join(
    os.path.dirname(os.path.dirname(__file__)), "public", "noteã®å¿ƒå¾—.md"
)
# noteã®å¿ƒå¾—.mdã®ãƒ‘ã‚¹
NOTE_SAMPLE_PATH = os.path.join(
    os.path.dirname(os.path.dirname(__file__)), "public", "ã‚µãƒ³ãƒ—ãƒ«_footer.md"
)


SMALL = "$${{\\footnotesize"
SMALL_END = "}}$$"


def convert_news_json_to_markdown(news_list: List[Dict]) -> str:
    now = datetime.now()
    header = f"""
ğŸ—“ï¸ç·¨é›†è€…ã‚³ãƒ¡ãƒ³ãƒˆï¼šãƒˆãƒ¬ãƒ³ãƒ‰ã‹ã‚‰æ¥­å‹™ã«å½¹ç«‹ã¤ITæŠ€è¡“ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã—ã¦AIãŒæ¯æ—¥è¦ç´„ã—ã¦ãŠçŸ¥ã‚‰ã›

---
"""
    body = ""
    for item in news_list:
        body += f"""
### {item['rank']}. {item['summaryTitle']}

{item['points'][0]}
{item['points'][1]}
{item['points'][2]}

[å¼•ç”¨å…ƒï¼š{item['title']}ï¼ˆ{item['users']} USERSï¼‰]({item['url']})

> {item['summary']}

---
"""
    ### [{item['rank']}. {item['summaryTitle']}]({item['url']})

    return header + body


def get_sunday(date: datetime) -> datetime:
    """æŒ‡å®šæ—¥ä»˜ã®é€±ã®æ—¥æ›œæ—¥ã‚’è¿”ã™"""
    return date - timedelta(days=date.weekday() + 1) if date.weekday() != 6 else date


def load_titles_from_weekly_txt(txt_path: str) -> set:
    if not os.path.exists(txt_path):
        return set()
    with open(txt_path, encoding="utf-8") as f:
        return set(line.strip() for line in f if line.strip())


def save_titles_to_weekly_txt(txt_path: str, titles: list):
    os.makedirs(os.path.dirname(txt_path), exist_ok=True)
    # æ—¢å­˜ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚‚è€ƒæ…®ã—ã¦é‡è¤‡ã—ãªã„ã‚ˆã†ã«è¿½è¨˜
    existing = load_titles_from_weekly_txt(txt_path)
    with open(txt_path, "a", encoding="utf-8") as f:
        for title in titles:
            if title not in existing:
                f.write(title + "\n")


def main(publish=False):
    entries = fetch_hatena_news_entries()
    if not entries:
        print("ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚»ãƒ¬ã‚¯ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return

    now = datetime.now()
    # historyãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’srcã®ä¸€ã¤ä¸Šã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«æŒ‡å®š
    history_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "history")
    os.makedirs(history_dir, exist_ok=True)
    history_filename = os.path.join(
        history_dir, f"history_{now.year}_{now.month:02d}_{now.day:02d}.txt"
    )

    # é€±ã”ã¨ã®ã‚¿ã‚¤ãƒˆãƒ«è¨˜éŒ²ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ±ºå®š
    sunday = get_sunday(now)
    weekly_txt_dir = os.path.join(
        history_dir, "txt", f"{sunday.year}_{sunday.month:02d}_{sunday.day:02d}"
    )
    os.makedirs(weekly_txt_dir, exist_ok=True)
    weekly_txt_path = os.path.join(weekly_txt_dir, "titles.txt")
    recorded_titles = load_titles_from_weekly_txt(weekly_txt_path)

    history = load_history(history_filename)
    # é€±ã”ã¨ã®è¨˜éŒ²æ¸ˆã‚¿ã‚¤ãƒˆãƒ«ã‚‚é™¤å¤–æ¡ä»¶ã«è¿½åŠ 
    top_entries = [
        item
        for item in entries
        if item["title"] not in history and item["title"] not in recorded_titles
    ][:30]

    # top_entriesã‚’ãƒˆãƒƒãƒ—7ã«çµã‚Šè¾¼ã‚€
    top_entries = top_entries[:RANK_LIMIT]

    # top_entriesã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’é€±ã”ã¨ã®txtã«è¨˜éŒ²
    save_titles_to_weekly_txt(weekly_txt_path, [item["title"] for item in top_entries])

    # rank, usersã‚‚å«ã‚ã¦jsonä¿å­˜ï¼ˆusersã¯intå‹ã§ä¿å­˜ï¼‰
    json_dir = os.path.join(
        os.path.dirname(os.path.dirname(__file__)), "history", "json"
    )
    os.makedirs(json_dir, exist_ok=True)
    json_filename = os.path.join(
        json_dir,
        f"news_{now.year}_{now.month:02d}_{now.day:02d}_{now.hour:02d}_{now.minute:02d}.json",
    )
    entries_for_json = []
    # noteã®å¿ƒå¾—.mdã‚’èª­ã¿è¾¼ã‚€
    with open(NOTE_KOKOROE_PATH, encoding="utf-8") as f:
        note_kokoroe = f.read()
        # print(note_kokoroe)
    with open(NOTE_SAMPLE_PATH, encoding="utf-8") as f:
        note_sample = f.read()
    for idx, item in enumerate(top_entries):
        try:
            users_num = int(item["users"].replace(",", "")) if item["users"] else 0
        except Exception:
            users_num = 0
        entry = {
            "rank": idx + 1,
            "url": item["url"],
            "title": item["title"],
            "users": users_num,
        }

        summary = ""
        if item["url"]:
            urlBody = fetch_article_content_from_url(item["url"])
            results = simple(
                topic=f"""ã‚ãªãŸã¯ãƒ—ãƒ­ã®ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚
ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰è¨˜äº‹ã§ä¸€ç•ªä¼ãˆãŸã„éƒ¨åˆ†ã‚’è€ƒå¯Ÿã—ã€
1è¡Œç›®ã«è‡ªåˆ†ãªã‚Šã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å…ˆé ­ã«çµµæ–‡å­—ä»˜ãã§20æ–‡å­—ç¨‹åº¦ã§ã€
2~4è¡Œç›®ã®3è¡Œã«ãƒ»ã‹ã‚‰å§‹ã¾ã‚‹ç®‡æ¡æ›¸ãï¼ˆè¨˜å·ãªã—ï¼‰ã§1è¡Œã¯40æ–‡å­—(80byte)ãªã®ã§ãã‚Œä»¥ä¸‹ã€
5è¡Œç›®ä»¥é™ã«300æ–‡å­—ä»¥å†…ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚
å…ˆé ­ã‚„æ–‡æœ«ã«ï½ã‚’ã¾ã¨ã‚ã¾ã—ãŸã‚„æ”¹è¡Œãªã©ã®æƒ…å ±ã¯ä¸è¦ã§ã™ã€‚

ã‚¿ã‚¤ãƒˆãƒ«: {item['title']}
è¨˜äº‹: {urlBody}""",
            )
            summary = results[0]
            if summary:
                lines = [line for line in summary.split("\n") if line.strip()]
                entry["summaryTitle"] = lines[0]
                entry["points"] = lines[1:4]
                entry["summary"] = "\n".join(lines[4:]).strip()

        entries_for_json.append(entry)
    save_history_json(json_filename, entries_for_json)
    markdown = convert_news_json_to_markdown(entries_for_json)

    results_eval = simple(
        topic=f"""æ¬¡ã®ã¾ã¨ã‚ãŸè¨˜äº‹ã‚’ç·è©•ã—ã¦1è¡Œç›®ã«è¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã‚­ãƒ£ãƒƒãƒãƒ¼ãªã‚¢ã‚¤ãƒ‡ã‚¢ã§ã€ä»¥é™ã¯ç·è©•ã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚ç®‡æ¡æ›¸ãã®å ´åˆã¯ï¼ˆè¨˜å·ãªã—ï¼‰ã§1è¡Œã¯30æ–‡å­—(60byte)ãªã®ã§ãã‚Œä»¥ä¸‹ã€‚å¾ŒåŠã«ã¯æ±ºã¾ã‚Šæ–‡å¥ã¨ã€æœ€å¾Œã®è¡Œã«ã¯ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚
å…ˆé ­ã‚„æ–‡æœ«ã«ï½ã‚’ã¾ã¨ã‚ã¾ã—ãŸã‚„```markdownã€ãªã©ã®æƒ…å ±ã¯ä¸è¦ã§ã™ã€‚

ã€æ§‹æˆã¯ä¸‹è¨˜ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’æ„è­˜ã—ã¦ãã ã•ã„ã€‘
{note_sample}

ã€è¨˜äº‹ã€‘
{markdown}""",
    )
    linesEval = [line for line in results_eval[0].split("\n")]
    markdown = (
        TEMPLATE_TITLE
        + linesEval[0]
        + "\n"
        + markdown
        + "\n"
        + "\n".join(linesEval[1:])
    )

    # markdownã‚’history/mdãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜
    md_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "history", "md")
    os.makedirs(md_dir, exist_ok=True)
    md_filename = os.path.join(
        md_dir,
        f"news_{now.year}_{now.month:02d}_{now.day:02d}_{now.hour:02d}_{now.minute:02d}.md",
    )
    with open(md_filename, "w", encoding="utf-8") as f:
        f.write(markdown)

    asyncio.run(post_note(md_filename, headless=False, publish=publish))


if __name__ == "__main__":
    arg = sys.argv[1].lower() if len(sys.argv) > 1 else None
    if arg == "true":
        publish = True
    else:
        publish = False
    main(publish=publish)
