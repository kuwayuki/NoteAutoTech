import os
from datetime import datetime
from hatena_scraper import fetch_hatena_news_entries, fetch_article_content_from_url
from history_manager import (
    load_history,
    save_history_json,
    load_history_json,
)
from utils import simple
from post_note import main as post_note
from typing import List, Dict
import asyncio
import sys

# noteã®å¿ƒå¾—.mdã®ãƒ‘ã‚¹
NOTE_KOKOROE_PATH = os.path.join(
    os.path.dirname(os.path.dirname(__file__)), "public", "noteã®å¿ƒå¾—.md"
)
# noteã®å¿ƒå¾—.mdã®ãƒ‘ã‚¹
NOTE_SAMPLE_PATH = os.path.join(
    os.path.dirname(os.path.dirname(__file__)), "public", "ã‚µãƒ³ãƒ—ãƒ«_footer.md"
)

RANK_LIMIT = 5


def convert_news_json_to_markdown(news_list: List[Dict]) -> str:
    now = datetime.now()
    today = f"{now.year}/{now.month}/{now.day} {now.hour}:00"
    header = f"""# ã€{today} æœ€æ–°ã€‘æ¯æ—¥ãŸã£ãŸ 5 åˆ†ã§æŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’æ´ã‚€ï¼

ğŸ—“ï¸ ç·¨é›†è€…ã‚³ãƒ¡ãƒ³ãƒˆï¼š
è©±é¡Œã®ä¸­ã‹ã‚‰ã€ã€Œå®Ÿå‹™ã«å½¹ç«‹ã¤ã€ã€Œæœ¬è³ªçš„ãªç¤ºå”†ãŒã‚ã‚‹ã€ã€Œæœªæ¥ã«å½±éŸ¿ã‚’ä¸ãˆãã†ãªæŠ€è¡“ã€ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã—ã¦ã€æ¯æ—¥æ•°æœ¬ã‚’å³é¸ã—ã¦ã„ã¾ã™ã€‚å˜ãªã‚‹ãƒˆãƒ¬ãƒ³ãƒ‰ç´¹ä»‹ã§ã¯ãªãã€å®Ÿå‹™è€…ç›®ç·šã§ã®è¦ç‚¹æ•´ç†ã¨è§£é‡ˆã‚’åŠ ãˆã¦ã„ã¾ã™ã€‚

---
"""
    body = ""
    for item in news_list:
        body += f"""
## {item['rank']}. {item['summaryTitle']}

[{item['title']}]({item['url']})

**ğŸ” ãƒã‚¤ãƒ³ãƒˆè¦ç´„**:
**{item['points'][0]}**
**{item['points'][1]}**
**{item['points'][2]}**

> {item['summary']}

---
"""

    return header + body


def main(publish=False):
    entries = fetch_hatena_news_entries()
    if not entries:
        print("ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚»ãƒ¬ã‚¯ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return

    now = datetime.now()
    # historyãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’srcã®ä¸€ã¤ä¸Šã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«æŒ‡å®š
    history_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "history")
    os.makedirs(history_dir, exist_ok=True)
    history_filename = os.path.join(
        history_dir, f"history_{now.year}_{now.month:02d}_{now.day:02d}.txt"
    )

    history = load_history(history_filename)
    top_entries = [item for item in entries if item["title"] not in history][:20]
    news_titles_text = ""
    for idx, item in enumerate(top_entries):
        news_titles_text += f"{idx+1}. {item['title']} ({item['date']}) {item['users']} USERS\n{item['url']}\n\n"

    # rank, usersã‚‚å«ã‚ã¦jsonä¿å­˜ï¼ˆusersã¯intå‹ã§ä¿å­˜ï¼‰
    json_dir = os.path.join(
        os.path.dirname(os.path.dirname(__file__)), "history", "json"
    )
    os.makedirs(json_dir, exist_ok=True)
    json_filename = os.path.join(
        json_dir,
        f"news_{now.year}_{now.month:02d}_{now.day:02d}_{now.hour:02d}_{now.minute:02d}.json",
    )
    entries_for_json = []
    # noteã®å¿ƒå¾—.mdã‚’èª­ã¿è¾¼ã‚€
    with open(NOTE_KOKOROE_PATH, encoding="utf-8") as f:
        note_kokoroe = f.read()
        # print(note_kokoroe)
    with open(NOTE_SAMPLE_PATH, encoding="utf-8") as f:
        note_sample = f.read()
    for idx, item in enumerate(entries):
        try:
            users_num = int(item["users"].replace(",", "")) if item["users"] else 0
        except Exception:
            users_num = 0
        entry = {
            "rank": idx + 1,
            "url": item["url"],
            "title": item["title"],
            "users": users_num,
        }

        summary = ""
        if idx < RANK_LIMIT and item["url"]:
            urlBody = fetch_article_content_from_url(item["url"])
            results = simple(
                topic=f"ã‚ãªãŸã¯ãƒ—ãƒ­ã®ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰è¨˜äº‹ã§ä¸€ç•ªä¼ãˆãŸã„éƒ¨åˆ†ã‚’è€ƒå¯Ÿã—ã€1è¡Œç›®ã«è‡ªåˆ†ãªã‚Šã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å…ˆé ­ã«çµµæ–‡å­—ä»˜ãã§20æ–‡å­—ç¨‹åº¦ã§ã€2~4è¡Œç›®ã®3è¡Œã«ãƒ»ã‹ã‚‰å§‹ã¾ã‚‹ç®‡æ¡æ›¸ãï¼ˆè¨˜å·ãªã—ï¼‰ã§1è¡Œã¯30æ–‡å­—(60byte)ãªã®ã§ãã‚Œä»¥ä¸‹ã€5è¡Œç›®ä»¥é™ã«300æ–‡å­—ä»¥å†…ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚å…ˆé ­ã‚„æ–‡æœ«ã«ï½ã‚’ã¾ã¨ã‚ã¾ã—ãŸã‚„æ”¹è¡Œãªã©ã®æƒ…å ±ã¯ä¸è¦ã§ã™ã€‚\nã‚¿ã‚¤ãƒˆãƒ«: {item['title']}\nè¨˜äº‹: {urlBody}",
            )
            summary = results[0]
            if summary:
                lines = [line for line in summary.split("\n") if line.strip()]
                entry["summaryTitle"] = lines[0]
                entry["points"] = lines[1:4]
                entry["summary"] = "\n".join(lines[4:]).strip()
        if idx < RANK_LIMIT:
            entries_for_json.append(entry)
    save_history_json(json_filename, entries_for_json)
    markdown = convert_news_json_to_markdown(entries_for_json)

    results_eval = simple(
        topic=f"æ¬¡ã®ã¾ã¨ã‚ãŸè¨˜äº‹ã‚’ç·è©•ã—ã¦ãã ã•ã„ã€‚å…ˆé ­ã‚„æ–‡æœ«ã«ï½ã‚’ã¾ã¨ã‚ã¾ã—ãŸã‚„```markdownã€ãªã©ã®æƒ…å ±ã¯ä¸è¦ã§ã™ã€‚\nã€æ§‹æˆã¯ä¸‹è¨˜ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’æ„è­˜ã—ã¦ãã ã•ã„ã€‘\n{note_sample}\n\nã€è¨˜äº‹ã€‘\n{markdown}",
    )
    markdown += "\n" + results_eval[0]
    print(markdown)

    # markdownã‚’history/mdãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜
    md_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "history", "md")
    os.makedirs(md_dir, exist_ok=True)
    md_filename = os.path.join(
        md_dir,
        f"news_{now.year}_{now.month:02d}_{now.day:02d}_{now.hour:02d}_{now.minute:02d}.md",
    )
    with open(md_filename, "w", encoding="utf-8") as f:
        f.write(markdown)

    asyncio.run(post_note(md_filename, headless=False, publish=publish))


if __name__ == "__main__":
    arg = sys.argv[1].lower() if len(sys.argv) > 1 else None
    if arg == "true":
        publish = True
    else:
        publish = False
    main(publish=publish)
